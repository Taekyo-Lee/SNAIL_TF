{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Dense, Identity\n",
    "import math, copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Single-user RL agent : 진척율 70%\n",
    "### 2. Meta learner : 진척율 : 20%\n",
    "### 3. Language models : 진척율 : 0% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(Layer):\n",
    "    def __init__(self, num_out_features, dilation_rate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = num_out_features\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self.conv1d_1 = tf.keras.layers.Conv1D(filters=self.filters, kernel_size=2, padding='causal', dilation_rate=self.dilation_rate)\n",
    "        self.conv1d_2 = tf.keras.layers.Conv1D(filters=self.filters, kernel_size=2, padding='causal', dilation_rate=self.dilation_rate)\n",
    "\n",
    "    def call(self, input):\n",
    "        \"\"\"\n",
    "        input_shape : (minibatch_size, seq_len, num_features)\n",
    "        output_shape : (minibatch_size, seq_len, num_features+self.filters) \n",
    "        \"\"\"\n",
    "        xf, xg = self.conv1d_1(input), self.conv1d_2(input)\n",
    "        activations = tf.keras.activations.tanh(xf)*tf.keras.activations.tanh(xg)\n",
    "        output = tf.concat([input, activations], axis=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCBlock(Model):\n",
    "    def __init__(self, seq_len, num_in_features, num_out_features, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seq_len = seq_len\n",
    "        self.num_in_features = num_in_features\n",
    "        self.num_out_features = num_out_features\n",
    "        self.tcblock = self.get_tcblock()\n",
    "\n",
    "    def get_tcblock(self):\n",
    "        input = tf.keras.Input(shape=(self.seq_len, self.num_in_features))\n",
    "        num_dilation = int(math.ceil(math.log(self.seq_len, 2)))\n",
    "        x = DenseBlock(num_out_features=self.num_out_features, dilation_rate=2)(input)\n",
    "        for i in range(2, num_dilation+1):\n",
    "            x = DenseBlock(num_out_features=self.num_out_features, dilation_rate=int(math.pow(2, i)))(x)\n",
    "        TCBlock = Model(inputs=input, outputs=x)\n",
    "        return TCBlock\n",
    "        \n",
    "    def call(self, input):\n",
    "        \"\"\"\n",
    "        input_shape : (minibatch_size, seq_len, num_features)\n",
    "        output_shape : (minibatch_size, seq_len, num_features+ceil(log_2_seq_len)*self.filters) \n",
    "        \"\"\"\n",
    "        return self.tcblock(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(Model):\n",
    "    def __init__(self, seq_len, key_dim, val_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seq_len = seq_len\n",
    "        self.key_dim = key_dim\n",
    "        self.val_dim = val_dim\n",
    "        self.query_layer = Dense(self.key_dim)\n",
    "        self.key_layer = Dense(self.key_dim)\n",
    "        self.value_layer = Dense(self.val_dim)\n",
    "        self.sqrt_k = math.sqrt(self.key_dim)\n",
    "        self.mask = tf.where(tf.linalg.band_part(tf.ones(shape=(self.seq_len, self.seq_len)), -1, 0) == 0, float('-inf'), 0) \n",
    "\n",
    "    def call(self, input):\n",
    "        \"\"\"\n",
    "        input_shape : (minibatch_size, seq_len, num_features)\n",
    "        output_shape : (minibatch_size, seq_len, num_features+key_dim) \n",
    "        \"\"\"\n",
    "        queries = self.query_layer(input)\n",
    "        keys = self.key_layer(input)\n",
    "        values = self.value_layer(input)\n",
    "        logits = tf.linalg.matmul(queries, keys, transpose_b=True)/self.sqrt_k\n",
    "        logits += self.mask \n",
    "        probs = tf.nn.softmax(logits)\n",
    "        read = tf.linalg.matmul(probs, values)\n",
    "        output = tf.concat([input, read], axis=-1)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sanil_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " tc_block_3 (TCBlock)        multiple                  176       \n",
      "                                                                 \n",
      " tc_block_4 (TCBlock)        multiple                  432       \n",
      "                                                                 \n",
      " attention_block_2 (Attentio  multiple                 114       \n",
      " nBlock)                                                         \n",
      "                                                                 \n",
      " tc_block_5 (TCBlock)        multiple                  752       \n",
      "                                                                 \n",
      " attention_block_3 (Attentio  multiple                 261       \n",
      " nBlock)                                                         \n",
      "                                                                 \n",
      " identity_1 (Identity)       multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,735\n",
      "Trainable params: 1,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class SANIL(Model):\n",
    "    def __init__(self, seq_len, num_in_features, architecture, output_layer=None, **kwargs):\n",
    "        \"\"\"\n",
    "        A Tensorflow implementation of the SANIL model from 'A Simple Neural Attentive Meta-Learner' by Nikhil Mishra et al. (https://arxiv.org/abs/1707.03141).\n",
    "        Permission is hereby granted, free of charge, to any person.\n",
    "        \"\"\"        \n",
    "        super().__init__(**kwargs)        \n",
    "        self.seq_len = seq_len\n",
    "        self.num_in_features = num_in_features\n",
    "        self.architecture = architecture\n",
    "        self.snail_layers = []\n",
    "        self.changed_in_features = self.num_in_features\n",
    "        for layer_info in self.architecture:\n",
    "            try:\n",
    "                self.snail_layers.append( TCBlock(seq_len=self.seq_len, num_in_features=self.changed_in_features, num_out_features=layer_info['tc']) )\n",
    "                self.changed_in_features += int(math.ceil(math.log(self.seq_len, 2)))*layer_info['tc']          \n",
    "            except:\n",
    "                self.snail_layers.append( AttentionBlock(seq_len=self.seq_len, key_dim=layer_info['attention'][0], val_dim=layer_info['attention'][1]) )\n",
    "                self.changed_in_features += layer_info['attention'][1]  \n",
    "        if output_layer:\n",
    "            self.output_layer = copy.deepcopy(output_layer)\n",
    "        else:\n",
    "            self.output_layer = Identity(trainable=False)\n",
    "\n",
    "                \n",
    "    def call(self, input, vervose=False):\n",
    "        x = input\n",
    "        if vervose : print(f'input_shape: {x.shape}')\n",
    "        for layer in self.snail_layers:\n",
    "            x = layer(x)\n",
    "            if vervose : print(f'x_shape: {x.shape}')\n",
    "        output = self.output_layer(x)\n",
    "        if vervose : print(f'output_shape: {output.shape}')\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "minibatch_size = 2\n",
    "seq_len, num_in_features = 10, 2\n",
    "architecture = ( {'tc':2}, {'tc':2}, {'attention':[2, 2]}, {'tc':2}, {'attention':[3, 3]} )\n",
    "snail = SANIL(seq_len, num_in_features, architecture)\n",
    "input = tf.random.normal(shape=(minibatch_size, seq_len, num_in_features))\n",
    "snail(input)\n",
    "snail.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFMAAAA8CAYAAAAaEIaPAAAABmJLR0QA/wD/AP+gvaeTAAAEAUlEQVR4nO2cQUgqXRTH/1OfgUJpRiSkixZFLcRFBNFKCkFIEcJwUUGLylatDILATdAioygIgnbtrEBJ2lTgKm0ZQVBBESQhGZEgmpRzvsUjwdSP9x4n32fv/mAWc+Z475kf99656KBERAQBB7s1f7qC74SQyYiQyYiQycg/nwPRaBQrKyt/opaqYnd3tyhWNDLv7++xt7dXkYKqkVgsVtZP0cj8oJR5AbCzswOXy1XymlgzGREyGREyGREyGREyGREyGREyGREyGREyGREyGREyGREyGREyGflrZC4vL0OSJEiSBL1e/yV9fEuZqVQK7e3tsNls+ZjH4wERwWQyfVm/31ImEUGWZciyXNF+y345XM3U19fj5uam4v1+y5H5p2CXmc1m4fV60dnZCZVKBa1WC7vdjv39feRyuXze+/s7/H4/LBYLdDodlEoljEYj1tbWCqZnMBjMPzgkScLd3R1cLhc0Gg2amppgs9kKRuHn/NfXV+5bLA99wu/3U4nwTzMxMUFqtZoODw8pnU5TPB4nj8dDACgcDufzQqEQAaDFxUV6fn6mRCJB6+vrVFNTQx6Pp6hdh8NBAMjhcFAkEqFUKkVHR0ekVCqpp6enbH4mkymIm0wmam1t/e37+w8/O+wy29raqK+vryje0dFRJNNsNhfljY6OkkKhoGQyWRD/kBMKhQriTqeTAFAikSiZX0mZ7NPcarUiEolgamoKp6en+al9dXUFs9mcz7PZbAiHw0WfN5lMeHt7w8XFRcn2e3p6Cs4NBgMA4OHhgekOfh92mRsbG9je3sbt7S0GBgbQ0NAAq9WKQCBQkJdMJuH1emE0GtHY2Jhf42ZnZwEA6XS6ZPtqtbrgvK6uDgAqvg0qBbtMSZIwNjaG4+NjvLy8IBgMgogwNDRU8KaI3W7HwsICJicncX19DVmWQURYXV0F8GOvWG2wy9RoNLi8vAQAKBQKWCyW/BP24OAAAJDL5XBycgKdToeZmRk0NzdDkiQAQCaT4S6pYnzJPnN6ehrn5+fIZrN4fHzE0tISiAj9/f0AgNraWpjNZsTjcfh8Pjw9PSGTySAcDmNzc/MrSqoMv/C0+inOzs7I7XZTV1cXqVQq0mq11NvbS1tbWyTLcj4vkUiQ2+0mg8FACoWCWlpaaHx8nObm5ggAAaDu7m6KRqP5849jfn6e6Mc6UHAMDg5SIBAoio+MjJDP5yvbzq9Q0a3Rd6eiW6O/GSGTESGTESGTESGTESGTESGTESGTESGTESGTESGTESGTESGTESGTESGTESGTESGTkbIvbg0PD1eyjqohFouVvVY0Mg0GA5xO55cWVM3o9fqyfiSiKvyB+v+J+CseToRMRoRMRoRMRv4FIVc1n2+SGWUAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(snail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('snail_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6515a690a6dbe8a09209fafde5522a3d83e04aeba1c97bf643df8a4816aaac1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
